name: Test and Validate

on:
  push:
    branches: [ main, master, develop ]
  pull_request:
    branches: [ main, master ]

env:
  CARGO_TERM_COLOR: always
  RUST_BACKTRACE: 1

jobs:
  validate-content:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v4
    
    - name: Setup Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
    
    - name: Install Python dependencies
      run: |
        python -m pip install --upgrade pip
        pip install requests beautifulsoup4 markdown
    
    - name: Setup mdBook
      uses: peaceiris/actions-mdbook@v1
      with:
        mdbook-version: 'latest'
    
    - name: Validate book configuration
      run: |
        # Check that book.toml exists and is valid
        test -f book.toml
        mdbook build --dest-dir book-test
        echo "✅ Book configuration is valid"
    
    - name: Validate SUMMARY.md structure
      run: |
        # Check SUMMARY.md exists and has proper structure
        test -f src/SUMMARY.md
        # Check that all files referenced in SUMMARY.md exist
        python3 -c "
        import re
        import os
        
        with open('src/SUMMARY.md', 'r') as f:
            content = f.read()
        
        # Find all markdown file references
        links = re.findall(r'\[.*?\]\((.*?\.md)\)', content)
        missing_files = []
        
        for link in links:
            file_path = os.path.join('src', link)
            if not os.path.exists(file_path):
                missing_files.append(file_path)
        
        if missing_files:
            print('❌ Missing files referenced in SUMMARY.md:')
            for f in missing_files:
                print(f'  - {f}')
            exit(1)
        else:
            print('✅ All files referenced in SUMMARY.md exist')
        "
    
    - name: Test link validation
      run: |
        # Run existing link validation if available
        if [ -f "link_validator.py" ]; then
          python link_validator.py
          echo "✅ Link validation completed"
        else
          echo "⚠️  Link validator not found, skipping detailed link validation"
        fi
    
    - name: Test build output
      run: |
        # Build and verify key pages exist
        mdbook build
        
        # Check critical files exist
        required_files=(
          "book/index.html"
          "book/introduction.html"
          "book/print.html"
        )
        
        for file in "${required_files[@]}"; do
          if [ ! -f "$file" ]; then
            echo "❌ Missing required file: $file"
            exit 1
          fi
        done
        
        # Check that chapters have been built
        required_dirs=(
          "book/core-concepts"
          "book/cryptography"
          "book/embedded-patterns"
          "book/migration"
          "book/quick-reference"
        )
        
        for dir in "${required_dirs[@]}"; do
          if [ ! -d "$dir" ]; then
            echo "❌ Missing required directory: $dir"
            exit 1
          fi
        done
        
        echo "✅ All required build outputs present"
    
    - name: Test search functionality
      run: |
        # Check that search index is generated
        if [ -f "book/searchindex.js" ]; then
          echo "✅ Search index generated successfully"
        else
          echo "❌ Search index not found"
          exit 1
        fi

  # Parallel testing matrix for different Rust targets and scenarios
  test-rust-std:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        rust-version: [stable, beta]
        include:
          - rust-version: stable
            cache-key: stable
          - rust-version: beta
            cache-key: beta
    steps:
    - uses: actions/checkout@v4
    
    - name: Cache Rust dependencies
      uses: actions/cache@v3
      with:
        path: |
          ~/.cargo/registry
          ~/.cargo/git
          target
        key: ${{ runner.os }}-cargo-${{ matrix.cache-key }}-${{ hashFiles('**/Cargo.lock') }}
        restore-keys: |
          ${{ runner.os }}-cargo-${{ matrix.cache-key }}-
          ${{ runner.os }}-cargo-
    
    - name: Setup Rust ${{ matrix.rust-version }}
      uses: actions-rs/toolchain@v1
      with:
        toolchain: ${{ matrix.rust-version }}
        override: true
        components: rustfmt, clippy
    
    - name: Build testing framework
      run: |
        echo "🔨 Building Rust std testing framework with ${{ matrix.rust-version }}..."
        cargo build --bin rust_example_tester --release
        echo "✅ Framework built successfully"
    
    - name: Run comprehensive std tests
      run: |
        echo "🦀 Running comprehensive std compilation tests..."
        cargo test --test comprehensive_compilation_tests --release -- test_std_examples_compilation
        echo "✅ Std compilation tests completed"
    
    - name: Upload std test results
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: std-test-results-${{ matrix.rust-version }}
        path: target/release/deps/comprehensive_compilation_tests-*

  test-rust-embedded:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        target: 
          - thumbv7em-none-eabihf
          - thumbv6m-none-eabi
          - thumbv7m-none-eabi
        include:
          - target: thumbv7em-none-eabihf
            features: "cortex-m,embedded-hal"
          - target: thumbv6m-none-eabi
            features: "cortex-m"
          - target: thumbv7m-none-eabi
            features: "cortex-m,embedded-hal"
    steps:
    - uses: actions/checkout@v4
    
    - name: Cache Rust dependencies
      uses: actions/cache@v3
      with:
        path: |
          ~/.cargo/registry
          ~/.cargo/git
          target
        key: ${{ runner.os }}-cargo-embedded-${{ matrix.target }}-${{ hashFiles('**/Cargo.lock') }}
        restore-keys: |
          ${{ runner.os }}-cargo-embedded-
          ${{ runner.os }}-cargo-
    
    - name: Setup Rust with embedded target
      uses: actions-rs/toolchain@v1
      with:
        toolchain: stable
        override: true
        components: rustfmt, clippy
        targets: ${{ matrix.target }}
    
    - name: Build embedded testing framework
      run: |
        echo "🔨 Building embedded testing framework for ${{ matrix.target }}..."
        cargo build --bin rust_example_tester --release --features embedded
        echo "✅ Embedded framework built successfully"
    
    - name: Run embedded compilation tests
      run: |
        echo "🎯 Running embedded compilation tests for ${{ matrix.target }}..."
        cargo test --test comprehensive_compilation_tests --release --features embedded -- test_embedded_target_compilation
        echo "✅ Embedded tests completed for ${{ matrix.target }}"
    
    - name: Upload embedded test results
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: embedded-test-results-${{ matrix.target }}
        path: target/release/deps/comprehensive_compilation_tests-*

  test-rust-crypto:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v4
    
    - name: Cache Rust dependencies
      uses: actions/cache@v3
      with:
        path: |
          ~/.cargo/registry
          ~/.cargo/git
          target
        key: ${{ runner.os }}-cargo-crypto-${{ hashFiles('**/Cargo.lock') }}
        restore-keys: |
          ${{ runner.os }}-cargo-crypto-
          ${{ runner.os }}-cargo-
    
    - name: Setup Rust
      uses: actions-rs/toolchain@v1
      with:
        toolchain: stable
        override: true
        components: rustfmt, clippy
    
    - name: Build crypto testing framework
      run: |
        echo "🔨 Building crypto testing framework..."
        cargo build --bin security_validator_cli --release
        echo "✅ Crypto framework built successfully"
    
    - name: Run crypto compilation tests
      run: |
        echo "🔐 Running crypto compilation tests..."
        cargo test --test comprehensive_compilation_tests --release -- test_crypto_examples_compilation
        cargo test --test security_validation_tests --release
        echo "✅ Crypto tests completed"
    
    - name: Upload crypto test results
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: crypto-test-results
        path: |
          target/release/deps/comprehensive_compilation_tests-*
          target/release/deps/security_validation_tests-*

  performance-benchmarks:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v4
    
    - name: Cache Rust dependencies
      uses: actions/cache@v3
      with:
        path: |
          ~/.cargo/registry
          ~/.cargo/git
          target
        key: ${{ runner.os }}-cargo-perf-${{ hashFiles('**/Cargo.lock') }}
        restore-keys: |
          ${{ runner.os }}-cargo-perf-
          ${{ runner.os }}-cargo-
    
    - name: Setup Rust
      uses: actions-rs/toolchain@v1
      with:
        toolchain: stable
        override: true
        components: rustfmt, clippy
    
    - name: Install performance monitoring tools
      run: |
        sudo apt-get update
        sudo apt-get install -y time valgrind
    
    - name: Build performance testing framework
      run: |
        echo "🔨 Building performance testing framework..."
        cargo build --bin rust_example_tester --release
        echo "✅ Performance framework built successfully"
    
    - name: Run performance benchmarks
      run: |
        echo "⚡ Running performance benchmarks..."
        cargo test --test performance_benchmarks --release -- --nocapture
        echo "✅ Performance benchmarks completed"
    
    - name: Generate performance report
      run: |
        echo "📊 Generating performance report..."
        echo "# Performance Benchmark Results" > performance_report.md
        echo "Generated on: $(date)" >> performance_report.md
        echo "" >> performance_report.md
        echo "## Compilation Performance" >> performance_report.md
        cargo test --test performance_benchmarks --release -- benchmark_single_compilation_speed --nocapture 2>&1 | grep -E "(Compilation time|test result)" >> performance_report.md
        echo "" >> performance_report.md
        echo "## Parallel Compilation Performance" >> performance_report.md
        cargo test --test performance_benchmarks --release -- benchmark_parallel_compilation --nocapture 2>&1 | grep -E "(Parallel compilation|test result)" >> performance_report.md
        echo "✅ Performance report generated"
    
    - name: Upload performance results
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: performance-results
        path: |
          performance_report.md
          target/release/deps/performance_benchmarks-*

  test-rust-examples:
    runs-on: ubuntu-latest
    needs: [test-rust-std, test-rust-embedded, test-rust-crypto]
    steps:
    - uses: actions/checkout@v4
    
    - name: Cache Rust dependencies
      uses: actions/cache@v3
      with:
        path: |
          ~/.cargo/registry
          ~/.cargo/git
          target
        key: ${{ runner.os }}-cargo-integration-${{ hashFiles('**/Cargo.lock') }}
        restore-keys: |
          ${{ runner.os }}-cargo-integration-
          ${{ runner.os }}-cargo-
    
    - name: Setup Rust
      uses: actions-rs/toolchain@v1
      with:
        toolchain: stable
        override: true
        components: rustfmt, clippy
        targets: thumbv7em-none-eabihf
    
    - name: Build Rust compilation testing framework
      run: |
        echo "🔨 Building Rust example testing framework..."
        cargo build --bin rust_example_tester --release
        echo "✅ Rust testing framework built successfully"
    
    - name: Test Rust code examples with compilation framework
      run: |
        echo "🦀 Testing Rust code examples with advanced compilation testing..."
        
        # Test with the main tutorial document if available
        if [ -f "embedded-rust-tutorial-master.md" ]; then
          timeout 300 ./target/release/rust_example_tester embedded-rust-tutorial-master.md > rust_compilation_results.json
          echo "✅ Advanced Rust compilation testing completed"
          
          # Display summary
          echo "📊 Compilation Test Summary:"
          if command -v jq &> /dev/null; then
            cat rust_compilation_results.json | jq -r '"Total examples: \(.total_examples), Successful: \(.successful), Failed: \(.failed), Success rate: \(.success_rate)%"'
          else
            echo "Results saved to rust_compilation_results.json"
          fi
        else
          echo "⚠️  Main tutorial document not found, testing individual files..."
          
          # Test individual markdown files in src/ with parallel processing
          find src -name "*.md" -type f | head -10 | xargs -P 4 -I {} bash -c '
            echo "Testing {}..."
            if timeout 60 ./target/release/rust_example_tester "{}" > /dev/null 2>&1; then
              echo "✅ {} passed"
            else
              echo "⚠️  {} had issues"
            fi
          '
        fi
    
    - name: Run legacy Rust validation
      run: |
        # Run existing Rust validation if available
        if [ -f "validate_new_content.rs" ]; then
          rustc validate_new_content.rs -o validate_content
          timeout 120 ./validate_content
          echo "✅ Legacy Rust code examples validated"
        else
          echo "⚠️  Legacy Rust validator not found, skipping"
        fi
    
    - name: Upload compilation test results
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: rust-compilation-results
        path: |
          rust_compilation_results.json
          code_test_report.md

  metrics-collection:
    runs-on: ubuntu-latest
    needs: [test-rust-std, test-rust-embedded, test-rust-crypto, performance-benchmarks]
    if: always()
    steps:
    - uses: actions/checkout@v4
    
    - name: Setup Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
    
    - name: Setup Rust
      uses: actions-rs/toolchain@v1
      with:
        toolchain: stable
        override: true
        targets: thumbv7em-none-eabihf
    
    - name: Download all test artifacts
      uses: actions/download-artifact@v3
      with:
        path: test-artifacts
    
    - name: Install Python dependencies
      run: |
        python -m pip install --upgrade pip
        pip install requests beautifulsoup4 markdown
    
    - name: Collect and analyze CI metrics
      run: |
        echo "📊 Collecting comprehensive CI/CD metrics..."
        python scripts/ci_metrics_monitor.py --report --output ci_metrics_report.md
        echo "✅ Metrics collection completed"
    
    - name: Display metrics summary
      run: |
        echo "📈 CI/CD Metrics Summary:"
        if [ -f "ci_metrics_report.md" ]; then
          head -30 ci_metrics_report.md
        else
          echo "⚠️  Metrics report not generated"
        fi
    
    - name: Upload metrics report
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: ci-metrics-report
        path: |
          ci_metrics_report.md
          ci_metrics/*.json
    
    - name: Check metrics thresholds
      run: |
        echo "🎯 Checking performance thresholds..."
        python -c "
        import json
        import sys
        
        # Load metrics if available
        try:
            with open('ci_metrics_report.md', 'r') as f:
                content = f.read()
            
            # Simple threshold checks
            if 'Build Success**: False' in content:
                print('❌ Build failure detected')
                sys.exit(1)
            elif 'Test Success**: False' in content:
                print('❌ Test failure detected')
                sys.exit(1)
            else:
                print('✅ All thresholds passed')
        except Exception as e:
            print(f'⚠️  Could not check thresholds: {e}')
        "

  integration-testing:
    runs-on: ubuntu-latest
    needs: [validate-content, test-rust-examples, metrics-collection]
    if: always()
    steps:
    - uses: actions/checkout@v4
    
    - name: Setup Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
    
    - name: Setup Rust
      uses: actions-rs/toolchain@v1
      with:
        toolchain: stable
        override: true
        targets: thumbv7em-none-eabihf
    
    - name: Install Python dependencies
      run: |
        python -m pip install --upgrade pip
        pip install requests beautifulsoup4 markdown
    
    - name: Build Rust compilation testing framework
      run: |
        echo "🔨 Building Rust example testing framework for integration..."
        cargo build --bin rust_example_tester
    
    - name: Run integrated validation with Rust compilation testing
      run: |
        echo "🔗 Running integrated validation with Rust compilation testing..."
        
        # Test with the main tutorial document if available
        if [ -f "embedded-rust-tutorial-master.md" ]; then
          echo "📚 Testing main tutorial document with integrated validation..."
          python validate_tutorial.py embedded-rust-tutorial-master.md
          echo "✅ Integrated validation completed"
        else
          echo "⚠️  Main tutorial document not found, testing with src/introduction.md..."
          python validate_tutorial.py src/introduction.md
        fi
    
    - name: Run comprehensive validation suite
      run: |
        echo "🎯 Running comprehensive validation suite..."
        if [ -f "comprehensive_validation_suite.py" ]; then
          python comprehensive_validation_suite.py
          echo "✅ Comprehensive validation suite completed"
        else
          echo "⚠️  Comprehensive validation suite not found"
        fi
    
    - name: Upload integration test results
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: integration-test-results
        path: |
          code_test_report.md
          task14_comprehensive_validation_report.md
          task14_comprehensive_validation_results.json
          validation_report.md